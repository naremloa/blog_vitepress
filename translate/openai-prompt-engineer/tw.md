<!-- #region title -->
<h1>提示工程</h1>
<!-- #endregion title -->

這份指南分享了從大型語言模型（有時會稱為 GPT 模型），如 GPT-4o 中獲得更好結果的策略和方案。這裏描述的方法有時可以結合使用以達到更好的效果。我們鼓勵多進行實驗，以找出最符合你需求的方法。

你也可以探索這些 prompts 的範例，這些範例展示了我們的模型能夠達到的效果：

[**Prompt examples**](https://platform.openai.com/examples)

## 獲得更好結果的 6 個策略

### 撰寫清晰的指示

這些模型無法知道你的想法。如果輸出內容太長，要求簡短的回覆。如果輸出內容太過簡單，要求專家級別的輸出內容。如果你不喜歡輸出的格式，示範你希望看到的格式。模型需要猜測的越少，你越有可能得到你想要的結果。

方案：

- 在你的請求中包含更多細節，以獲得更相關的答案
- 要求模型採用某個特定角色的語氣或風格
- 使用分隔符來清楚的標示輸入的不同部分
- 明確說明完成任務所需的步驟
- 提供範例
- 明確說明需要的輸出長度

### 提供參考文本

語言模型可能會自信的捏造答案，特別是在被問一些深奧的話題，或引文和網址時。就像筆記能幫助學生在考試中表現更好一樣，提供參考的文本給這些模型可以減少它們捏造的部分。

方案：

- 指示模型使用參考文本來回答問題。
- 指示模型使用參考文本的引文來回答問題。

## 將複雜的任務拆分為相對簡單的子任務

就如在軟體工程中將複雜系統拆解成一系列模組化組件是一個好的方向，對於提交給語言模型的任務也應該如此。複雜任務的錯誤率往往高於簡單任務。此外，複雜任務通常可以用多個簡單任務的構成的工作流程來替代，流程中較早執行的任務的輸出會被用來作為較晚執行的任務的輸入。

方案：

- 使用 intent classification 來識別用戶的請求中最相關的指示。
- 對於需要進行非常長的對話的應用，總結或篩選前面對話過的內容。
- 將長文件進行分段摘要，並遞歸的執行，以構建一個完整摘要。

## 給模型時間來“思考”

如果你被問 17 乘以 28 是多少，你可能無法立即得出答案，但仍然可以通過一些時間計算出來。相同的，模型立即回答問題時會更容易出錯，而花時間計算的話，錯誤就會下降。要求模型在回答之前進行 chain of thought ，可以幫助模型更可靠的推理出正確答案。

方案：

- 在得到結論前，指示模型自行找出解決方案。
- 使用內在的獨白或是一系列的請求來隱藏模型的思考過程。
- 詢問模型在前面的執行中是否有遺漏東西

## 使用外部的工具

使用其他工具的輸出來彌補模型的弱點。例如，文本檢索系統（有時稱為 RAG 或是檢索增強生成）可以向模型提供相關文件資訊。像是 OpenAI 的 Code Interpreter 這樣的程式執行引擎可以幫助模型進行數學運算和程式執行。如果某項任務可以通過工具更可靠或高效的完成，相比分配給語言模型，分配給工具可以獲得更好的效果。

方案：

- 使用 embeddings-based 的搜索來實現高效的知識檢索。
- 使用執行的程式進行更精確的計算，或是呼叫外部 API 。
- 賦予模型權限訪問特定功能

## 系統的測試修改

如果可以量化模型的表現，才能相對容易的進行提升。在某些情況下，對提示的修改可能會在少數獨立的例子上取得更好的表現，但在更具代表性的多數例子上整體的表現出現下降。因此，為了確保對提示的修改能保持對模型的總體表現的影響是正面的，可能有必要定義一個全面的 test suite 。

方案：

- 參考標準答案來評估模型的輸出

# 方案

上面列出的每個策略都可以通過具體的方案實現。這些方案是為了提供一些可嘗試的方向。它們並非是完全全面的，所以你可以任意的嘗試任何未在這裡列出的想法。
